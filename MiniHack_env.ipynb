{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9ca85df9-344e-4404-9ec6-12f3ca53a5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import minihack\n",
    "from nle import nethack\n",
    "from gym import spaces\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f199c59a-6e83-4356-8e79-724330c36d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;37m#\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[1;37m@\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;37m<\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;37m#\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \n",
      "\u001b[0;37mA\u001b[0;37mg\u001b[0;37me\u001b[0;37mn\u001b[0;37mt\u001b[0;30m \u001b[0;37mt\u001b[0;37mh\u001b[0;37me\u001b[0;30m \u001b[0;37mT\u001b[0;37mr\u001b[0;37mo\u001b[0;37mg\u001b[0;37ml\u001b[0;37mo\u001b[0;37md\u001b[0;37my\u001b[0;37mt\u001b[0;37me\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;37mS\u001b[0;37mt\u001b[0;37m:\u001b[0;37m1\u001b[0;37m8\u001b[0;37m/\u001b[0;37m0\u001b[0;37m4\u001b[0;30m \u001b[0;37mD\u001b[0;37mx\u001b[0;37m:\u001b[0;37m1\u001b[0;37m1\u001b[0;30m \u001b[0;37mC\u001b[0;37mo\u001b[0;37m:\u001b[0;37m1\u001b[0;37m5\u001b[0;30m \u001b[0;37mI\u001b[0;37mn\u001b[0;37m:\u001b[0;37m8\u001b[0;30m \u001b[0;37mW\u001b[0;37mi\u001b[0;37m:\u001b[0;37m1\u001b[0;37m2\u001b[0;30m \u001b[0;37mC\u001b[0;37mh\u001b[0;37m:\u001b[0;37m7\u001b[0;30m \u001b[0;37mN\u001b[0;37me\u001b[0;37mu\u001b[0;37mt\u001b[0;37mr\u001b[0;37ma\u001b[0;37ml\u001b[0;30m \u001b[0;37mS\u001b[0;37m:\u001b[0;37m0\u001b[0;30m \n",
      "\u001b[0;37mD\u001b[0;37ml\u001b[0;37mv\u001b[0;37ml\u001b[0;37m:\u001b[0;37m1\u001b[0;30m \u001b[0;37m$\u001b[0;37m:\u001b[0;37m0\u001b[0;30m \u001b[0;37mH\u001b[0;37mP\u001b[0;37m:\u001b[0;37m1\u001b[0;37m6\u001b[0;37m(\u001b[0;37m1\u001b[0;37m6\u001b[0;37m)\u001b[0;30m \u001b[0;37mP\u001b[0;37mw\u001b[0;37m:\u001b[0;37m2\u001b[0;37m(\u001b[0;37m2\u001b[0;37m)\u001b[0;30m \u001b[0;37mA\u001b[0;37mC\u001b[0;37m:\u001b[0;37m8\u001b[0;30m \u001b[0;37mX\u001b[0;37mp\u001b[0;37m:\u001b[0;37m1\u001b[0;37m/\u001b[0;37m0\u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0;30m \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MiniHack-Quest-Hard-v0', \n",
    "               observation_keys=(\"glyphs\", \"chars\", \"colors\", \"specials\",\n",
    "                                 \"glyphs_crop\", \"chars_crop\", \"colors_crop\", \"specials_crop\",\n",
    "                                 \"blstats\", \"message\", \"inv_letters\",\n",
    "                                 \"inv_strs\", \"inv_glyphs\", \"inv_oclasses\"), \n",
    "              )\n",
    "env.reset()\n",
    "state, reward, done, info = env.step(0)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e58e489-7228-4c91-a717-91cdc4b0542f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(78)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "69ec5d66-41fd-4880-a460-0411880706ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glyphs\n",
      "(21, 79)\n",
      "[[2359 2359 2359 ... 2359 2359 2359]\n",
      " [2359 2359 2359 ... 2359 2359 2359]\n",
      " [2359 2359 2359 ... 2359 2359 2359]\n",
      " ...\n",
      " [2359 2359 2359 ... 2359 2359 2359]\n",
      " [2359 2359 2359 ... 2359 2359 2359]\n",
      " [2359 2359 2359 ... 2359 2359 2359]]\n",
      "chars\n",
      "(21, 79)\n",
      "[[32 32 32 ... 32 32 32]\n",
      " [32 32 32 ... 32 32 32]\n",
      " [32 32 32 ... 32 32 32]\n",
      " ...\n",
      " [32 32 32 ... 32 32 32]\n",
      " [32 32 32 ... 32 32 32]\n",
      " [32 32 32 ... 32 32 32]]\n",
      "colors\n",
      "(21, 79)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "specials\n",
      "(21, 79)\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "glyphs_crop\n",
      "(9, 9)\n",
      "[[   0    0 2359 2359 2359 2359 2359 2359 2359]\n",
      " [   0    0 2359 2359 2359 2359 2359 2359 2359]\n",
      " [   0    0 2359 2359 2359 2359 2359 2359 2359]\n",
      " [   0    0 2359 2359 2380 2359 2359 2359 2359]\n",
      " [   0    0 2359 2359  329 2359 2359 2359 2359]\n",
      " [   0    0 2359 2359 2382 2359 2359 2359 2359]\n",
      " [   0    0 2359 2359 2380 2359 2359 2359 2359]\n",
      " [   0    0 2359 2359 2359 2359 2359 2359 2359]\n",
      " [   0    0 2359 2359 2359 2359 2359 2359 2359]]\n",
      "chars_crop\n",
      "(9, 9)\n",
      "[[ 0  0 32 32 32 32 32 32 32]\n",
      " [ 0  0 32 32 32 32 32 32 32]\n",
      " [ 0  0 32 32 32 32 32 32 32]\n",
      " [ 0  0 32 32 35 32 32 32 32]\n",
      " [ 0  0 32 32 64 32 32 32 32]\n",
      " [ 0  0 32 32 60 32 32 32 32]\n",
      " [ 0  0 32 32 35 32 32 32 32]\n",
      " [ 0  0 32 32 32 32 32 32 32]\n",
      " [ 0  0 32 32 32 32 32 32 32]]\n",
      "colors_crop\n",
      "(9, 9)\n",
      "[[ 0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  7  0  0  0  0]\n",
      " [ 0  0  0  0 15  0  0  0  0]\n",
      " [ 0  0  0  0  7  0  0  0  0]\n",
      " [ 0  0  0  0  7  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n",
      "specials_crop\n",
      "(9, 9)\n",
      "[[0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "blstats\n",
      "(26,)\n",
      "[ 2  6 19 22 11 15  8 12  7  0 16 16  1  0  2  2  8  0  1  0  2  1  0  0\n",
      "  1  0]\n",
      "message\n",
      "(256,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "inv_letters\n",
      "(55,)\n",
      "[ 97  98  99 100 101   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0]\n",
      "inv_strs\n",
      "(55, 80)\n",
      "[[97 32 43 ...  0  0  0]\n",
      " [97 32 43 ...  0  0  0]\n",
      " [49 51 32 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]\n",
      " [ 0  0  0 ...  0  0  0]]\n",
      "inv_glyphs\n",
      "(55,)\n",
      "[1965 1975 2351 2352 2019 5976 5976 5976 5976 5976 5976 5976 5976 5976\n",
      " 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976\n",
      " 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976\n",
      " 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976 5976]\n",
      "inv_oclasses\n",
      "(55,)\n",
      "[ 2  2 13 13  3 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18\n",
      " 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18 18\n",
      " 18 18 18 18 18 18 18]\n"
     ]
    }
   ],
   "source": [
    "for i in state.keys():\n",
    "    print(i)\n",
    "    print(state[i].shape)\n",
    "    print(state[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc05d8b-df54-4a20-a2b2-92e06f051502",
   "metadata": {},
   "source": [
    "## CNN 1: 9 x 9 crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cef046b7-2f9a-4de1-affd-195d38884463",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 9, 9])\n"
     ]
    }
   ],
   "source": [
    "crop_obs = [\"glyphs_crop\", \"chars_crop\", \"colors_crop\", \"specials_crop\"]\n",
    "crop_state = deque([], maxlen = len(crop_obs))\n",
    "for i in crop_obs:\n",
    "    crop_state.append(state[i])\n",
    "crop_state = torch.tensor(np.array(crop_state), dtype=torch.float).unsqueeze(0)\n",
    "print(crop_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e9fff4c9-9d9b-4cc8-b6df-3eb2e95df47c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space torch.Size([4, 9, 9])\n",
      "1296\n",
      "torch.Size([1, 78])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class CNN_1(nn.Module):\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        super().__init__()\n",
    "        observation_space = torch.squeeze(observation_space)\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(observation_space.shape[0], 16, 3, stride=1, padding=1), #channels, outgoing_filters, kernerl_size, stride/no_of_frames\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),   \n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.input_dim = self.conv_layers(torch.zeros(1, *observation_space.shape)).view(1, -1).size(1)\n",
    "        #print(self.input_dim)\n",
    "\n",
    "        self.conn_layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, action_space.n)\n",
    "        )\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.conn_layers(x)\n",
    "        return x\n",
    "    \n",
    "model = CNN_1(crop_state, env.action_space)\n",
    "x = model.forward(crop_state.to(model.device))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c95d78f-272c-4f04-ad13-c369aae2459c",
   "metadata": {},
   "source": [
    "## CNN 2: Whole State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "401dd5be-95d8-492b-9d63-cc82ad59167a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 21, 79])\n"
     ]
    }
   ],
   "source": [
    "obs = [\"glyphs\", \"chars\", \"colors\", \"specials\"]\n",
    "whole_state = deque([], maxlen = len(obs))\n",
    "for i in obs:\n",
    "    whole_state.append(state[i])\n",
    "whole_state = torch.tensor(np.array(whole_state), dtype=torch.float).unsqueeze(0)\n",
    "print(whole_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dce192c5-82ea-4a94-92c4-47c7f1478ce5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 78])\n"
     ]
    }
   ],
   "source": [
    "class CNN_2(nn.Module):\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        super().__init__()\n",
    "        observation_space = torch.squeeze(observation_space)\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(observation_space.shape[0], 16, 3, stride=4, padding=1), #channels, outgoing_filters, kernerl_size, stride/no_of_frames\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),   \n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.input_dim = self.conv_layers(torch.zeros(1, *observation_space.shape)).view(1, -1).size(1)\n",
    "        #print(self.input_dim)\n",
    "\n",
    "        self.conn_layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, action_space.n)\n",
    "        )\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.conn_layers(x)\n",
    "        return x\n",
    "    \n",
    "model_2 = CNN_2(whole_state, env.action_space)\n",
    "x_2 = model_2.forward(whole_state.to(model_2.device))\n",
    "print(x_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd13eab-c92c-4249-b3fc-7ff217520c9f",
   "metadata": {},
   "source": [
    "## CNN 3: Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0f3b90cc-c7b6-4c52-8502-b56396896f24",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 55, 80])\n"
     ]
    }
   ],
   "source": [
    "inv_obs = [\"inv_strs\"]\n",
    "inv_state = deque([], maxlen = len(obs))\n",
    "for i in inv_obs:\n",
    "    #print(i)\n",
    "    #print(state[i].shape)\n",
    "    #print(state[i])\n",
    "    inv_state.append(state[i])\n",
    "inv_state = torch.tensor(np.array(inv_state), dtype=torch.float).unsqueeze(0)\n",
    "print(inv_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "7f62ce8e-4241-443b-901b-96cd09e865e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_space torch.Size([1, 55, 80])\n",
      "1120\n",
      "torch.Size([1, 78])\n"
     ]
    }
   ],
   "source": [
    "class CNN_3(nn.Module):\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        super().__init__()\n",
    "        observation_space = torch.squeeze(observation_space, 1)\n",
    "\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(observation_space.shape[0], 16, 3, stride=4, padding=1), #channels, outgoing_filters, kernerl_size, stride/no_of_frames\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),   \n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        #print(self.conv_layers)\n",
    "        self.input_dim = self.conv_layers(torch.zeros(1, *observation_space.shape)).view(1, -1).size(1)\n",
    "        print(self.input_dim)\n",
    "        #self.input_dim = self.get_dims(observation_space)\n",
    "\n",
    "        self.conn_layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, action_space.n)\n",
    "        )\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO Implement forward pass\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.conn_layers(x)\n",
    "        return x\n",
    "    \n",
    "model_3 = CNN_3(inv_state, env.action_space)\n",
    "x_3 = model_3.forward(inv_state.to(model_3.device))\n",
    "print(x_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6cc831-22e2-458b-ab45-afd2172cb493",
   "metadata": {},
   "source": [
    "## MLP 1: Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a660fec9-beb0-4cc6-bbea-8df94d3c0e23",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([447])\n"
     ]
    }
   ],
   "source": [
    "stats_obs = [\"blstats\", \"message\", \"inv_letters\", \"inv_glyphs\", \"inv_oclasses\"]\n",
    "stats_state = np.array([])\n",
    "for i in stats_obs:\n",
    "    #print(i)\n",
    "    #print(state[i].shape)\n",
    "    #print(state[i])\n",
    "    stats_state = np.append(stats_state, state[i])\n",
    "stats_state = torch.tensor(stats_state, dtype=torch.float)\n",
    "print(stats_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d238a819-160f-4c3f-9284-bd12150f1a4d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([78])\n"
     ]
    }
   ],
   "source": [
    "class MLP_1(nn.Module):\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        super().__init__()\n",
    "        self.input_dim = observation_space.shape[0]\n",
    "        #print(self.input_dim)\n",
    "\n",
    "        self.conn_layers = nn.Sequential(\n",
    "            nn.Linear(self.input_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, action_space.n)\n",
    "        )\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conn_layers(x)\n",
    "        return x\n",
    "    \n",
    "model_4 = MLP_1(stats_state, env.action_space)\n",
    "x_4 = model_4.forward(stats_state.to(model_4.device))\n",
    "print(x_4.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a0d415-f1de-47aa-b85b-87be9f1d9584",
   "metadata": {},
   "source": [
    "## Joint Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5a493e60-6f56-4b84-8431-9aea7ef9c5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "crop output:  1296\n",
      "whole output:  1920\n",
      "inventory output:  1120\n",
      "4848\n",
      "tensor(75, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class combined(nn.Module):\n",
    "    def __init__(self, obs_space_crop, obs_space_whole, obs_space_inv, obs_space_stats, action_space):\n",
    "        super().__init__()\n",
    "        self.action_space = action_space.n\n",
    "        print(self.action_space)\n",
    "        # CNN for cropped images\n",
    "        obs_space_crop = torch.squeeze(obs_space_crop)\n",
    "        \n",
    "        self.conv_1 = nn.Sequential(\n",
    "            nn.Conv2d(obs_space_crop.shape[0], 16, 3, stride=1, padding=1), #channels, outgoing_filters, kernerl_size, stride/no_of_frames\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),   \n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.input_dim_crop = self.conv_1(torch.zeros(1, *obs_space_crop.shape)).view(1, -1).size(1)\n",
    "        print('crop output: ',self.input_dim_crop)\n",
    "        \n",
    "        # CNN for whole images\n",
    "        \n",
    "        obs_space_whole = torch.squeeze(obs_space_whole)\n",
    "\n",
    "        self.conv_2 = nn.Sequential(\n",
    "            nn.Conv2d(obs_space_whole.shape[0], 16, 3, stride=4, padding=1), #channels, outgoing_filters, kernerl_size, stride/no_of_frames\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),   \n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.input_dim_whole = self.conv_2(torch.zeros(1, *obs_space_whole.shape)).view(1, -1).size(1)\n",
    "        print('whole output: ', self.input_dim_whole)\n",
    "        \n",
    "        \n",
    "        # CNN for Inventory\n",
    "        \n",
    "        obs_space_inv = torch.squeeze(obs_space_inv, 1)\n",
    "\n",
    "        self.conv_3 = nn.Sequential(\n",
    "            nn.Conv2d(obs_space_inv.shape[0], 16, 3, stride=4, padding=1), #channels, outgoing_filters, kernerl_size, stride/no_of_frames\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),   \n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.input_dim_inv = self.conv_3(torch.zeros(1, *obs_space_inv.shape)).view(1, -1).size(1)\n",
    "        print('inventory output: ', self.input_dim_inv)\n",
    "        \n",
    "        # MLP_1\n",
    "        \n",
    "        self.input_dim_mlp = obs_space_stats.shape[0]\n",
    "        self.output_dim_mlp = 512\n",
    "        self.mlp_1 = nn.Sequential(\n",
    "            nn.Linear(self.input_dim_mlp, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.output_dim_mlp)\n",
    "        )\n",
    "        \n",
    "        # Fully Connected 2nd Layer\n",
    "        \n",
    "        print(self.input_dim_crop+self.input_dim_whole+self.input_dim_inv+self.output_dim_mlp)\n",
    "        self.fc1_output = 1024\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(self.input_dim_crop+self.input_dim_whole+self.input_dim_inv+self.output_dim_mlp, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, self.fc1_output)\n",
    "        )\n",
    "        \n",
    "        # LSTM\n",
    "        \n",
    "        self.lstm_size = self.fc1_output\n",
    "        self.num_layers = 2\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.lstm_size,\n",
    "            hidden_size=self.lstm_size,\n",
    "            num_layers=self.num_layers,\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(self.fc1_output, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, self.action_space),\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, crop, whole, inv, stats):\n",
    "        conv_1 = self.conv_1(crop).view(-1)\n",
    "        conv_2 = self.conv_2(whole).view(-1)\n",
    "        conv_3 = self.conv_3(inv).view(-1)\n",
    "        mlp_1 = self.mlp_1(stats).view(-1)\n",
    "        x = torch.cat([conv_1, conv_2, conv_3, mlp_1])\n",
    "        x = self.fc1(x)\n",
    "        #print(x.unsqueeze(0).shape)\n",
    "        #x, new_state = self.lstm(x.unsqueeze(0))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "full_model = combined(crop_state, whole_state, inv_state, stats_state, env.action_space)\n",
    "x_4 = full_model.forward(crop_state.to(full_model.device),whole_state.to(full_model.device),inv_state.to(full_model.device),stats_state.to(full_model.device))\n",
    "print(torch.argmax(x_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40541f7b-ae4b-4368-b4be-9194a9b497fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
